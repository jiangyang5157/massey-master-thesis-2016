%****************************************************************
% Chapter X
%****************************************************************
\label{chapter-discussion}
\chapter{Discussion}

%****************************************************************
In this paper, an immersive virtual reality Android application includes a remote database server and a graphic display system for geographic data visualization. Popping a smartphone into the Google Cardboard container and then strapping it to people's head may sound like funny, but it works and is a super low-cost way ($15$ US dollars) to experience virtual reality at this moment compare to other virtual reality specific device. After all, the Android phone contains all the necessary sensors and positioning systems to track device movements.

The KML format data source has been used for geographic data creation. It not only provide basic needs but also can link multiple KML data across different files by URLs, which guarantee the synchronous latest data. Furthur more, KML has been adopted by more and more people and scientists across the different industry. Thus, there is a mass of geographic data resources created by KML have been shared within geographic communities. For instance, existing virtual globe software Google Map and Google Earth.

The application has an easy-to-use, intuitive nature working mode. On the one hand, a user can make a six degrees of freedom (DOF) movement. Although due to the sensor fusion creates a huge drift during the nasty double integration process, I alternatively using the Step sensor (pedometer) as the pedestrian navigation instead of Linear Acceleration sensor. It allows the user to move forward in the current heading that satisfies user for navigating through all scene. On the other hand, the application enables the ability for the user to intuitively interact with the scene for a better understanding of information. For example, select a \code{Placemark} and view the details of the \code{Placemark} on a popup message board; display a \code{Placemark} related OBJ model, or any further information from a URL, such as an image, summarized Wikipedia, or plain text.

There are five human senses provide the information and passed to our brain for capturing our attention: sight ($70$\%), hearing ($20$\%), smell ($5$\%), touch ($4$\%), and taste ($1$\%) \cite{mazuryk.vr.1996}. The immersive virtual reality certainly improved the feedback of sight sense and hearing. Although spatial sound is not included in the application yet, but by the given the existing Spatial Audio technology (such as \cite{google.spatial-audio.2016}), it can easily use the spatial audio as a simultaneous response for "fooling" the hearing sense.

The application has $55$ to $60$ FPS when the there is less than 250 \code{Placemark} exist in the scene. Although, the space partition that optimizes the intersection test has been significantly improved the performance. However, there is a performance limitation of current implementation due to the expensive render call in Android OpenGL ES API. It has a high priority and needs to be solved by calling the function once for all the same objects (\code{Placemark}).

There is a limitation of gesture recognition and perception technology, in particular with smartphones that are designed to be less physical keys as the trend. Therefore a user can only do touching the screen and be staring at the target.

The application is simply developed with some unfinished features. A key requirement for environmental scientists is to be able to visualize four-dimensional data (i.e. time-dependent three-dimensional data). It does not just visualize the environment data from the data file which created from the different period, or a fake real-time data visualization by refreshing in a certain frequently rate. But, an implementation of dynamic graphic animation will be excellent to improve user understanding of environmental data visualization. In other words, an animation transform from one piece of time-dependent data visualization to another, just like watching a movie.

One of the main features of geographic data visualization is Level Of Detail (LOD) render based on the distance from the eyes to the target area. Detail textures could be separately prepared, and attached as the circumstances may require. It can also provide a solution to visualize a large amount of overlapping data.

More geometric shapes support is fascinating, such as lines and polygons. Implementation of multiple layer LOD in the scene will allow the user to see the details not only geographical map but also the architectural structure of different floors.

Regards at virtual reality visualization, there is always room for improvement. When it related to human intuitive nature system, the user experience will always be not real enough compare to the real world.

%****************************************************************
